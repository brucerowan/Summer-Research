**Summer Research**

*June 22, 2017*

Started learning how to use Github, started looking into what projects were available,
and how the structure of Data for Democracy works.

*June 25, 2017*

Spoke with the founder of D4D, and a few other active members. This me some ideas about what projects to join. 

*July 5, 2017*

I was able to finish Data for Democracy's [Github tutorial](https://github.com/Data4Democracy/github-playground)

*July 7, 2017*

Joined group [town-council](https://github.com/Data4Democracy/town-council).
I was interested in the similarites to Cal Poly's [Digital Democracy](http://www.iatpp.calpoly.edu/projects/digitaldemocracy.asp).

I was given the task to scrape the meeting minutes/agenda of the city of Berkely. 
This project is using a powerful but complicated webscraping framework called Scrapy. I spent about 2 days trying to understand the framework after getting one of their example scrapers to work on mycomputer. 
However, when I asked the project manager for help she said I should just wait because she was coming out with some sort of visualization or tutorial to help people get the hang of scrapy. 

*July 20, 2017*

Many cities use a common content management systems(cms) to post their meeting contents. Legistar is a common cms that was used by several cities. 
One member of town council made a template that could potentially scrape any city's meeting content.
I decided to be the one to test this template on the Legistar cities. 

*July 24, 2017* 

Using some object oriented programing in python, I was able to effectively create python files that were able to call the legistar template file for six cities in the Bay area: 
Hayward, Cupertino, Mountain View, San Mateo, San Leandro, and Sunnyvale.

*July 25, 2017*

Found a task through the [Indivisible group/project](https://github.com/Data4Democracy/indivisible).
The task is to create a training dataset to classify events to actions by scraping several websites.

*July 27, 2017*

I was able to create a webscraper using the beautiful soup package for the site https://www.risestronger.org/action. 
That was able to output a csv file that held event names and their action classification.

*July 28, 2017*

I was recruited to join a project interested in visualising public opinion polls, but want to finish the previous task before I look more into this.

*Augest 1, 2017*
Have been trying for a few days to scrape https://resistancenearme.org/ but ran into trouble. Tried asking for help, but I'm still stumped.




